# Learning
å•¥ä¹Ÿä¸ä¼š ä¸çŸ¥é“çš„å°±æŸ¥âœŠğŸ»
## TODO
- 3.1
- 3.2
- 3.4
- 4.1
- 4.2
- 5
## Paper Contents
### Abstract
be consistent to human perception

a specific supervised learning problem of classification, regression or ranking
- supervised learning ç›‘ç£å­¦ä¹ 
- classification åˆ†ç±»
- regression å›å½’
- ranking æ’åº

FBP is a computation problem with multiple paradigms
- multiple paradigms å¤šèŒƒå¼

propose a new diverse benchmark dataset
- benchmark dataset åŸºå‡†æ•°æ®é›†

totally 5500 frontal faces

diverse properties (male/female, Asian/Caucasian, ages)

diverse labels (face landmarks, beauty scores within [1, 5], beauty score distribution) 
- face landmarks äººè„¸ç‰¹å¾ç‚¹

allows different computational models with different FBP paradigms, such as appearance-based/shape-based facial beauty classification/regression model for male/female of Asian/Caucasian. 
- appearance-based åŸºäºå¤–è§‚çš„
- shape-based åŸºäºå½¢çŠ¶çš„
- classification model åˆ†ç±»æ¨¡å‹
- regression model å›å½’æ¨¡å‹

evaluated the SCUT-FBP5500 dataset for FBP using different combinations of feature and predictor, and various deep learning methods.
- combinations of feature ç‰¹å¾ç»„åˆ
- predictor é¢„æµ‹å™¨
### 1. Introduction
It has application potential in facial makeup synthesis/recommendation, content-based image retrieval, aesthetic surgery, or face beauti- fication.

It is involved with the formulation of visual representation and predictor for the abstract concept of facial beauty.
- visual representation å¯è§†åŒ–è¡¨ç°å½¢å¼

various data-driven models, were introduced into FBP. 

One line of the works follows the classic pattern recognition process, which constructs the FBP system using the combination of the hand-crafted features and the shallow predictors.
- hand-crafted æ‰‹å·¥åˆ¶ä½œçš„
- shallow predictors æµ…å±‚é¢„æµ‹

The related hand-crafted feature derived from visual recognition includes the geometric fea- tures, like the geometric ratios and landmark distances, and the texture features, like the Gabor/SIFT-like features. 
- geometric features å‡ ä½•ç‰¹å¾ 
- geometric ratios å‡ ä½•æ¯”ä¾‹
- landmark distances ç‰¹å¾ç‚¹è·ç¦»
- texture features çº¹ç†ç‰¹å¾

The hierarchial structure of the deep learning model allows to build an end-to-end FBP system that automatically learns both the representation and the predictor of facial beauty simultaneously from the data.

Many works indicate that FBP based on deep learning is superior to the shallow predictors with hand-crafted facial feature.

We find that FBP have been formulated the recognition of facial beauty as a specific supervised learning problem of classification, regression. It indicates that FBP is intrinsically a computation problem with multiple paradigms. 

Previous databases built under specific computation constrains would limit the performance and flexibility of the computational model trained on the dataset.

Both shallow prediction model with hand-crafted feature and the state-of-the-art deep learning models were evaluated on the dataset.

Main contributions: 
- Dataset 
- Benchmark Analysis 
- Facial Beauty Prediction Evaluation
### 2. Construction of SCUT-FBP5500 Dataset
#### 2.1 Face Images Collection
faces aged from 15 to 60 with neutral expression.

four subsets with different races and gender, including 2000 Asian females, 2000 Asian males, 750 Caucasian females and 750 Caucasian males.
#### 2.2 Facial Beauty Scores and Facial Landmarks
All the images are labeled with beauty scores ranging from [1, 5] by totally 60 volunteers

 The four subset, Asian male/female and Caucasian male/female, are labeled separately

 If the correlation coefficient of the two beauty score of the same faces is less than 0.7, the volunteer would be asked to rate this face once more to decide the final score.

 To allow geometric analysis of facial beauty, 86 facial landmarks are located to the significant facial components of each images.
 - geometric analysis
 - facial landmarks

A GUI landmarks location system is developed, where the original location of the landmarks are initialized by the active shape model (ASM) trained by the SCUT-FBP dataset. Then, the detected landmarks by ASM are modified manually by volunteers to ensure the accuracy.
### 3. Benckmark Analysis of the SCUT-FBP5500
We made benchmark analysis of the beauty scores, labelers and face landmarks of the SCUT-FBP5500 with different gender and races, including Asian female (AF), Asian male (AM), Caucasian female (CF) and Caucasian male (CM).
#### 3.1 Distribution of Beauty Scores
visualize the distribution respectively

preprocess the data and filter the outliers of the beauty scores. 
- preprocess the data æ•°æ®é¢„å¤„ç†
- filter the outliers è¿‡æ»¤å¼‚å¸¸å€¼

We regard the average score of all the 60 labelers as the ground-truth. If the score of specific labeler for the same face differs from the ground-truth over 2, the score is treated as outlier
- ground-truth æ ‡å‡†

we visualized the score distribution of the SCUT-FBP5500 using the preprocessed data for all the four subset, respectively.

Two distribution fitting schemes are used: one is Gaussian fitting, the other is piecewise fitting 
- Gaussian fitting é«˜æ–¯æ‹Ÿåˆ
- piecewise fitting åˆ†æ®µæ‹Ÿåˆ

The results indicates that the beauty scores of all the four subset can be approximately fitted by a mixed distribution model with two Gaussian components.
- Gaussian components é«˜æ–¯åˆ†é‡
#### 3.2 Standard Deviation of Beauty Scores
We calculate the standard deviation of the scores gathered from different labelers to the ground-truth
- standard deviation æ ‡å‡†å·®

illustrate the results as histogram and as box figure
- histogram ç›´æ–¹å›¾
- box figure ç®±å½¢å›¾ ç®±çº¿å›¾

the distribution of standard deviations is similar to Gaussian distribution

most of the standard deviations are within a reasonable range of [0.6, 0.7].
- reasonable range åˆç†èŒƒå›´
#### 3.3 Correlation of Male/Female Labelers
 investigate the correlation between the male and female Asian labelers for the beauty scores

 It is consistent to the psychological research that human have better facial beauty perception for the faces from the same race.
#### 3.4 PCA Analysis of Facial Geometry
We visualize the 86-points face landmarks of the dataset using principle component analysis(PCA). 
- principle component analysis(PCA) ä¸»æˆåˆ†åˆ†æ

Fig.6 illustrate the mean and the five first principle component of the facial geometry of Asian
- principle component ä¸»æˆåˆ†

the landmarks data of Caucasian share similar distribution to Asian faces

We observe that the face shape is one of the main component influence the face geometry of beauty
- face shape è„¸éƒ¨å½¢çŠ¶ï¼ˆæ˜¯è„¸å‹å˜›
### 4. FBP Evaluation via Hand-Crafted Feature and Shallow Predictor
we evaluate the SCUT-FBP5500 using the hand-crafted feature with shallow predictor
- hand-crafted æ‰‹å·¥åˆ¶ä½œçš„
- shallow predictors æµ…å±‚é¢„æµ‹
#### 4.1 Geometric Feature with Shallow Predictor
We extract a 18-dimensional ratio feature vector from the faces and formulate FBP based on different regression models, such as the linear regression(LR), Gaussian regression(GR), and support vector regression(SVR).
- 18-dimensional ratio feature vector 18ç»´æ¯”ä¾‹ç‰¹å¾å‘é‡
- regression models å›å½’æ¨¡å‹
- linear regression(LR) çº¿æ€§å›å½’
- Gaussian regression(GR) é«˜æ–¯å›å½’
- support vector regression(SVR) æ”¯æŒå‘é‡å›å½’

Comparison were performed for Caucasian and Asian subsets

the performance of different model are measured using pearson correlation coefficient (PC), maximum absolute error(MAE) and root mean square error(RMSE) after 10 folds cross validation
- pearson correlation coefficient(PC) çš®å°”é€Šç›¸å…³ç³»æ•°
- maximum absolute error (MAE) æœ€å¤§ç»å¯¹è¯¯å·®
- root mean square error (RMSE) å‡æ–¹æ ¹è¯¯å·®ï¼ˆæ ‡å‡†è¯¯å·®ï¼‰
- 10 folds cross validation 10æ¬¡äº¤å‰éªŒè¯

The results in Table can be regarded as a baseline for the geometric analysis of FBP.
- baseline åŸºçº¿
- geometric analysis å‡ ä½•åˆ†æ
#### 4.2 Appearance Feature with Shallow Predictor
We extract 40 Gabor feature maps from every original image in five directions and eight angles.

using two different sampling schemes that extracts some component of the Gabor feature maps as following:
- Sample 86-keypoints
- 64UniSample

use PCA to reduce the extracted feature dimension before we train the predictor. 
- the extracted feature dimension æå–çš„ç‰¹å¾ç»´æ•°

Week12è¿›åº¦å°±æ±‡æŠ¥åˆ°è¿™é‡Œä¸ºæ­¢ï¼Œå‰©ä¸‹çš„æ”¾åˆ°finalğŸ‘‹ğŸ»

---
### 5. FBP Evaluation via Deep Predictor
We evaluate three recently proposed CNN models with different structures for FBP, including AlexNet, ResNet-18 and ResNeXt-50:
- AlexNet <= 227*227 random crop of raw image
- ResNet-18 <= 224*224 random crop of raw image
- ResNeXt-50 <= 224*224 random crop of raw image

All these CNN models are trained by initializing weights using networks pre-trained on the ImageNet dataset.

Two different experiment settings as following:
- 5-fold cross validation
- 60% for train, 40% for test

The results illustrates that the deepest CNN-based ResNeXt-50 model obtains the best performance

all the deep CNN model are superior to the shallow predictor

It indicates the effectiveness and powerfulness of the end-to-end feature learning deep model for FBP.
- end-to-end feature learning ç«¯åˆ°ç«¯ç‰¹å¾å­¦ä¹ 

the accuracy of all the 5-fold cross validation is slightly higher than the results of the split of 60% training and 40% testing.
- 5-fold cross validation 5æ¬¡äº¤å‰éªŒè¯

data augmentation techniques may further improve the performance of the deep FBP model, which merits exploring in the future.
### 6. Conclusion
å°±ä¸€å°æ®µæ€»ç»“ï¼Œå†æ¬¡å¤¸äº†ä¸€æ³¢SCUT-FBP550ã€‚
## References
[æœºå™¨å­¦ä¹ ](https://zh.wikipedia.org/wiki/æœºå™¨å­¦ä¹ ) 

[äººå·¥ç¥ç»ç½‘ç»œ](https://zh.wikipedia.org/wiki/äººå·¥ç¥ç»ç½‘ç»œ) 

[å·ç§¯ç¥ç»ç½‘ç»œ](https://zh.wikipedia.org/wiki/å·ç§¯ç¥ç»ç½‘ç»œ)

[äº¤å‰éªŒè¯](https://zh.wikipedia.org/wiki/äº¤å‰éªŒè¯)

[è¿‡æ‹Ÿåˆ](https://zh.wikipedia.org/wiki/è¿‡æ‹Ÿåˆ)

[AlexNet](https://my.oschina.net/u/876354/blog/1633143)

[PyTorchä¸­æ–‡æ–‡æ¡£](https://pytorch-cn.readthedocs.io/zh/latest/)

[Pythonæ•°æ®å¯è§†åŒ–-ç®±å½¢å›¾](https://zhuanlan.zhihu.com/p/34720695)

[ç›¸å…³ç³»æ•°](https://baike.baidu.com/item/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/3109424?fr=aladdin)

[ç»å¯¹è¯¯å·®](https://baike.baidu.com/item/%E7%BB%9D%E5%AF%B9%E8%AF%AF%E5%B7%AE)

[å‡æ–¹æ ¹è¯¯å·®](https://baike.baidu.com/item/%E5%9D%87%E6%96%B9%E6%A0%B9%E8%AF%AF%E5%B7%AE)

[hand-craft](https://blog.csdn.net/qq_22194315/article/details/82704776)

[MacOSå®‰è£…caffe](https://zhuanlan.zhihu.com/p/46930024)

[CNNå…¥é—¨è®²è§£ï¼šä»€ä¹ˆæ˜¯å¾®è°ƒï¼ˆFine Tuneï¼‰ï¼Ÿ](https://zhuanlan.zhihu.com/p/35890660)

[active shape model (ASM)](http://ice.dlut.edu.cn/lu/ASM.html)

[ASM](https://blog.csdn.net/carson2005/article/details/8194317)

[Pythonä¹‹Sklearnä½¿ç”¨æ•™ç¨‹](https://blog.csdn.net/xiaoyi_eric/article/details/79952325)

[sklearn-docs](https://sklearn.apachecn.org/docs/0.21.3/50.html)

[sklearn-user-guide](https://scikit-learn.org/stable/user_guide.html)

[PCAä¸»æˆåˆ†åˆ†ææå–ç‰¹å¾è„¸](https://blog.csdn.net/u010975589/article/details/88025494)

[PCA-1](https://blog.csdn.net/weixin_42001089/article/details/79989788)

[PCA-2](https://blog.csdn.net/liangjun_feng/article/details/78664820)

[PCA-3](https://blog.csdn.net/u010975589/article/details/88025494)

[pythonè°ƒç”¨resnetæ¨¡å‹å¯¹äººè„¸å›¾ç‰‡è¿›è¡Œç‰¹å¾æå–å…¨è¿æ¥å±‚ç‰¹å¾å‘é‡](https://blog.csdn.net/zuqiutxy/article/details/71156593)

[æ•°æ®é¢„å¤„ç†ï¼ˆpythonï¼‰](https://www.jianshu.com/p/4f3d9a34d246)

[numpy tutorial](https://www.runoob.com/numpy/numpy-tutorial.html)